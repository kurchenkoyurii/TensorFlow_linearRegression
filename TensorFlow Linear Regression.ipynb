{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fef2c581",
   "metadata": {},
   "source": [
    "# Linear Regression (Titanic. Who will survive?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22214e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b13ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4de52",
   "metadata": {},
   "source": [
    "# Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32f60a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "                       'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "462e6531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d6091",
   "metadata": {},
   "source": [
    "### The TensorFlow model we are going to use requires that the data we pass it comes in as a tf.data.Dataset object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bae221",
   "metadata": {},
   "source": [
    "## Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "464655a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "    def input_function():  # inner function, this will be returned\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
    "        if shuffle:# if shuffle is True\n",
    "            ds = ds.shuffle(1000)  # randomize order of data\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
    "        return ds  # return a batch of the dataset\n",
    "    return input_function  # return a function object for use\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bb2476",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6edee5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\kurch\\AppData\\Local\\Temp\\tmp9z6hflm7\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\kurch\\\\AppData\\\\Local\\\\Temp\\\\tmp9z6hflm7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "# We create a linear estimtor by passing the feature columns we created earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790480cc",
   "metadata": {},
   "source": [
    "# Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37529a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7689394\n"
     ]
    }
   ],
   "source": [
    "linear_est.train(train_input_fn)  # train\n",
    "result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing on tetsing data\n",
    "\n",
    "clear_output()  # clears consoke output\n",
    "print(result['accuracy'])  # the result variable is simply a dict of stats about our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23812c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7689394,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.8365167,\n",
       " 'auc_precision_recall': 0.78730106,\n",
       " 'average_loss': 0.46954522,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.45840904,\n",
       " 'precision': 0.6979167,\n",
       " 'prediction/mean': 0.36632466,\n",
       " 'recall': 0.67676765,\n",
       " 'global_step': 400}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b8153",
   "metadata": {},
   "source": [
    "# Looking at predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2c6ffd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\kurch\\AppData\\Local\\Temp\\tmp9z6hflm7\\model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "pred_dicts = list(linear_est.predict(eval_input_fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "62b58a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in pred_dicts:\n",
    "    a=i['probabilities']\n",
    "    b=a[1]\n",
    "    l.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1fe3e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'Percent':l}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e53a87bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc=pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8c3dd453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.336013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.540120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0.789055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.059346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.419269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.154965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.379448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Percent  survived\n",
       "0    0.055263         0\n",
       "1    0.336013         0\n",
       "2    0.655468         1\n",
       "3    0.540120         1\n",
       "4    0.225505         1\n",
       "..        ...       ...\n",
       "259  0.789055         1\n",
       "260  0.059346         0\n",
       "261  0.419269         0\n",
       "262  0.154965         0\n",
       "263  0.379448         1\n",
       "\n",
       "[264 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([perc, y_eval],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "50feca28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                          male\n",
      "age                          34.0\n",
      "n_siblings_spouses              0\n",
      "parch                           0\n",
      "fare                         13.0\n",
      "class                      Second\n",
      "deck                            D\n",
      "embark_town           Southampton\n",
      "alone                           y\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dfeval.loc[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
